{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fisher Information.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aydin-utting/MPhys_QML/blob/master/QNN_Fisher_Information.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRE7zqhEn4Jx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51f0d5f7-db3d-4ff0-9a45-a64bb093625d"
      },
      "source": [
        "!pip install matplotlib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENyWCwe8pQjY"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BF0t_Z7biEK"
      },
      "source": [
        "import torch                                                                \r\n",
        "import torch.nn as nn\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "\r\n",
        "def jacobian(y, x, create_graph=False):                                                               \r\n",
        "    jac = []                                                                                          \r\n",
        "    flat_y = y.reshape(-1)                                                                            \r\n",
        "    grad_y = torch.zeros_like(flat_y)                                                                 \r\n",
        "    for i in range(len(flat_y)):                                                                      \r\n",
        "        grad_y[i] = 1.                                                                                \r\n",
        "        grad_x, = torch.autograd.grad(flat_y, x, grad_y, retain_graph=True, create_graph=create_graph)\r\n",
        "        jac.append(grad_x.reshape(x.shape))                                                           \r\n",
        "        grad_y[i] = 0.                                                                                \r\n",
        "    return torch.stack(jac).reshape(y.shape + x.shape)                                                \r\n",
        "                                                                                                      \r\n",
        "def hessian(y, x):                                                                                    \r\n",
        "    return jacobian(jacobian(y, x, create_graph=True), x)  \r\n",
        "\r\n",
        "def fisher(y,x):\r\n",
        "    j = jacobian(y, x, create_graph=True)\r\n",
        "    return torch.outer(j,j)                                        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "et7o54WoZvmx",
        "outputId": "7deabb84-6835-48a3-a26d-f23c78cfb391"
      },
      "source": [
        "n_samples = 100\r\n",
        "X0 = torch.tensor(np.array([[np.random.normal(loc=-1, scale=1), \r\n",
        "                np.random.normal(loc=1, scale=1),\r\n",
        "                np.random.normal(loc=-1, scale=1),\r\n",
        "                np.random.normal(loc=1, scale=1)] for i in range(n_samples//2)]),requires_grad=False)\r\n",
        "\r\n",
        "\r\n",
        "X1 = torch.tensor(np.array([[np.random.normal(loc=1, scale=1), \r\n",
        "                np.random.normal(loc=-1, scale=1),\r\n",
        "                np.random.normal(loc=1, scale=1),\r\n",
        "                np.random.normal(loc=-1, scale=1)] for i in range(n_samples//2)]),requires_grad=False)\r\n",
        "\r\n",
        "X = torch.cat((X0, X1),0)\r\n",
        "\r\n",
        "Y = torch.cat((torch.tensor(np.array([[1,0] for i in range(n_samples//2)])), \r\n",
        "               torch.tensor(np.array([[0,1] for i in range(n_samples//2)]))), 0)\r\n",
        "\r\n",
        "data = list(zip(X, Y))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def loss_single(prediction,label):\r\n",
        "  delta = prediction-label\r\n",
        "  return torch.dot(delta,delta)*1\r\n",
        "\r\n",
        "def model(x,w):\r\n",
        "  sig = nn.Sigmoid()\r\n",
        "  softmax = nn.Softmax()\r\n",
        "\r\n",
        "  layer_1 = torch.split(w,[16,24])\r\n",
        "  w_1 = layer_1[0].reshape(4,4)\r\n",
        "  x = sig(torch.matmul(x,w_1))\r\n",
        "\r\n",
        "  layer_2 = torch.split(layer_1[1],[16,8])\r\n",
        "  w_2 = layer_2[0].reshape(4,4)\r\n",
        "  x = sig(torch.matmul(x,w_2))\r\n",
        "\r\n",
        "  w_3 = layer_2[1].reshape(4,2)\r\n",
        "  x = torch.matmul(x,w_3)\r\n",
        "  f = x.copy()\r\n",
        "  x = softmax(x)\r\n",
        "\r\n",
        "  return f,x\r\n",
        "\r\n",
        "def loss_avg(data,w):\r\n",
        "  loss_tot = 0\r\n",
        "  Fisher = torch.zeros((40,40))\r\n",
        "  for x,y in data:\r\n",
        "      prediction = model(x,w)\r\n",
        "      loss_tot += loss_single(prediction[1],y)\r\n",
        "      Fisher += fisher(loss_single(prediction[1],y),w)\r\n",
        "      diag_pi = torch.diag(np.ones_like(w)*prediction[1])\r\n",
        "      pipiT= torch.outer(np.ones_like(w)*prediction[1],np.ones_like(w)*prediction[1])\r\n",
        "      jac = jacobian(prediction[0],w)\r\n",
        "      print(jac)\r\n",
        "      print(pipiT)\r\n",
        "      print(diag_pi)\r\n",
        "      print(torch.matmul(torch.matmul(jac,(diag_pi-pipiT),torch.transpose(jac))\r\n",
        "\r\n",
        "  return loss_tot/n_samples,Fisher/n_samples\r\n",
        "\r\n",
        "def normalise_fishers(Fishers):\r\n",
        "    num_samples = len(Fishers)\r\n",
        "    TrF_integral = (1 / num_samples) * np.sum(np.array([torch.trace(F) for F in Fishers]))\r\n",
        "    return [((40) / TrF_integral) * F for F in Fishers]\r\n",
        "\r\n",
        "\r\n",
        "n_iter = 100\r\n",
        "all_fishers = torch.zeros((n_iter,40,40))\r\n",
        "EVs = np.array([])\r\n",
        "FR = []\r\n",
        "Rank = []\r\n",
        "for i in range(n_iter):\r\n",
        "  w = torch.tensor(np.random.uniform(size=(40,),low=-1.0,high=1.0),requires_grad=True)\r\n",
        "  total_loss, Fisher = loss_avg(data,w)\r\n",
        "  all_fishers[i] = Fisher\r\n",
        "  with torch.no_grad():\r\n",
        "    Rank.append(torch.matrix_rank(Fisher).item())\r\n",
        "    Fw = np.matmul(Fisher.numpy(),w.numpy())\r\n",
        "    wFw = np.dot(w,Fw)\r\n",
        "    FR.append(wFw)\r\n",
        "\r\n",
        "normalised_fishers = normalise_fishers(all_fishers)\r\n",
        "\r\n",
        "for F in normalised_fishers:\r\n",
        "  EVs = np.append(EVs,torch.eig(F, eigenvectors=False,  out=None)[0][:,0].detach().numpy())\r\n",
        "  #print(EVs)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "print(\"Fisher\")\r\n",
        "x, bins, p=plt.hist(EVs, bins=5,rwidth=0.6,color='r',range=[0,4])\r\n",
        "for item in p:\r\n",
        "  item.set_height(item.get_height()/(40*n_iter))\r\n",
        "plt.ylim(0,1)\r\n",
        "plt.title(\"Classical NN - normalised\")\r\n",
        "plt.show()\r\n",
        "\r\n",
        "plt.hist(Rank)\r\n",
        "plt.title('matrix ranks for all Fisher')\r\n",
        "plt.show()\r\n",
        "plt.hist(FR)\r\n",
        "plt.title('Fisher-Rao norm for all Fisher')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0181,  0.0018,  0.0103,  ...,  0.0298, -0.0577,  0.0693],\n",
            "        [ 0.0018,  0.0021,  0.0055,  ..., -0.0081, -0.0128,  0.0226],\n",
            "        [ 0.0103,  0.0055, -0.0062,  ..., -0.1099,  0.0846, -0.1007],\n",
            "        ...,\n",
            "        [ 0.0298, -0.0081, -0.1099,  ..., -0.5202,  0.9951, -0.4345],\n",
            "        [-0.0577, -0.0128,  0.0846,  ...,  0.9951,  0.1852,  0.9393],\n",
            "        [ 0.0693,  0.0226, -0.1007,  ..., -0.4345,  0.9393, -0.3534]],\n",
            "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "tensor([[-4.7221e-02, -6.6579e-03, -9.2550e-04,  ..., -6.3094e-02,\n",
            "          1.5614e-02, -8.1908e-02],\n",
            "        [-6.6579e-03,  3.7497e-02,  1.7520e-03,  ..., -9.6799e-02,\n",
            "          4.6208e-02, -1.0133e-01],\n",
            "        [-9.2550e-04,  1.7520e-03,  1.4006e-02,  ...,  2.8013e-02,\n",
            "          8.5916e-04,  1.6802e-02],\n",
            "        ...,\n",
            "        [-6.3094e-02, -9.6799e-02,  2.8013e-02,  ..., -1.0147e+00,\n",
            "          2.7456e-01, -1.0217e+00],\n",
            "        [ 1.5614e-02,  4.6208e-02,  8.5916e-04,  ...,  2.7456e-01,\n",
            "          2.8105e-01,  2.6643e-01],\n",
            "        [-8.1908e-02, -1.0133e-01,  1.6802e-02,  ..., -1.0217e+00,\n",
            "          2.6643e-01, -1.0309e+00]], dtype=torch.float64,\n",
            "       grad_fn=<SubBackward0>)\n",
            "tensor([[ 2.1824e-02,  5.0605e-03,  6.0677e-03,  ...,  1.6707e-02,\n",
            "         -1.7287e-02,  7.3374e-03],\n",
            "        [ 5.0605e-03,  1.3673e-02,  5.5094e-03,  ..., -4.8358e-02,\n",
            "         -1.3514e-02,  2.9019e-02],\n",
            "        [ 6.0677e-03,  5.5094e-03, -2.3972e-04,  ..., -7.2917e-02,\n",
            "         -1.6019e-03,  7.0024e-03],\n",
            "        ...,\n",
            "        [ 1.6707e-02, -4.8358e-02, -7.2917e-02,  ..., -8.3654e-01,\n",
            "         -1.1166e-01, -2.5427e-01],\n",
            "        [-1.7287e-02, -1.3514e-02, -1.6019e-03,  ..., -1.1166e-01,\n",
            "         -1.2410e-02, -4.6289e-02],\n",
            "        [ 7.3374e-03,  2.9019e-02,  7.0024e-03,  ..., -2.5427e-01,\n",
            "         -4.6289e-02, -7.7515e-02]], dtype=torch.float64,\n",
            "       grad_fn=<SubBackward0>)\n",
            "tensor([[-1.2906e-02, -6.8213e-04,  7.2584e-03,  ..., -1.5839e-02,\n",
            "         -3.2277e-02, -1.1990e-02],\n",
            "        [-6.8213e-04,  2.4905e-02, -9.1540e-04,  ..., -7.1303e-03,\n",
            "          2.8706e-02,  1.6926e-02],\n",
            "        [ 7.2584e-03, -9.1540e-04,  2.8339e-02,  ..., -1.5711e-03,\n",
            "         -1.2233e-02, -2.4135e-02],\n",
            "        ...,\n",
            "        [-1.5839e-02, -7.1303e-03, -1.5711e-03,  ...,  4.2841e-01,\n",
            "         -5.7120e-02,  3.8436e-01],\n",
            "        [-3.2277e-02,  2.8706e-02, -1.2233e-02,  ..., -5.7120e-02,\n",
            "         -2.6405e+00, -3.2434e-01],\n",
            "        [-1.1990e-02,  1.6926e-02, -2.4135e-02,  ...,  3.8436e-01,\n",
            "         -3.2434e-01,  3.9909e-01]], dtype=torch.float64,\n",
            "       grad_fn=<SubBackward0>)\n",
            "tensor([[-2.8085e-02, -1.8314e-03,  1.0140e-03,  ...,  6.0917e-02,\n",
            "         -2.3078e-02,  3.2280e-02],\n",
            "        [-1.8314e-03,  2.2531e-02,  6.4921e-04,  ...,  4.2010e-02,\n",
            "          6.6088e-03,  3.1917e-02],\n",
            "        [ 1.0140e-03,  6.4921e-04,  5.8965e-03,  ..., -2.7015e-02,\n",
            "         -3.5621e-03,  4.7869e-03],\n",
            "        ...,\n",
            "        [ 6.0917e-02,  4.2010e-02, -2.7015e-02,  ..., -2.3006e+00,\n",
            "         -7.4956e-01, -2.0016e+00],\n",
            "        [-2.3078e-02,  6.6088e-03, -3.5621e-03,  ..., -7.4956e-01,\n",
            "         -2.2834e-01, -8.0683e-01],\n",
            "        [ 3.2280e-02,  3.1917e-02,  4.7869e-03,  ..., -2.0016e+00,\n",
            "         -8.0683e-01, -1.7629e+00]], dtype=torch.float64,\n",
            "       grad_fn=<SubBackward0>)\n",
            "tensor([[-1.2913e-02,  8.3091e-04,  1.4789e-03,  ..., -7.5119e-03,\n",
            "         -2.3203e-02, -7.5598e-03],\n",
            "        [ 8.3091e-04, -8.1401e-03,  9.1134e-04,  ...,  9.6005e-03,\n",
            "          2.7573e-02, -1.1905e-02],\n",
            "        [ 1.4789e-03,  9.1134e-04,  1.6672e-02,  ..., -8.6148e-03,\n",
            "         -6.0582e-03, -8.5598e-03],\n",
            "        ...,\n",
            "        [-7.5119e-03,  9.6005e-03, -8.6148e-03,  ...,  4.3808e-01,\n",
            "          1.6136e-01,  4.5037e-01],\n",
            "        [-2.3203e-02,  2.7573e-02, -6.0582e-03,  ...,  1.6136e-01,\n",
            "         -1.5411e+00,  1.3023e-01],\n",
            "        [-7.5598e-03, -1.1905e-02, -8.5598e-03,  ...,  4.5037e-01,\n",
            "          1.3023e-01,  4.6510e-01]], dtype=torch.float64,\n",
            "       grad_fn=<SubBackward0>)\n",
            "tensor([[-3.0141e-02,  2.4727e-03, -2.7814e-04,  ...,  1.6621e-02,\n",
            "         -3.1095e-02,  3.7020e-02],\n",
            "        [ 2.4727e-03,  5.5211e-03, -1.1862e-04,  ...,  6.5003e-03,\n",
            "         -5.1289e-02,  5.7730e-02],\n",
            "        [-2.7814e-04, -1.1862e-04,  1.7385e-02,  ..., -5.9712e-03,\n",
            "         -1.7042e-02,  1.9428e-02],\n",
            "        ...,\n",
            "        [ 1.6621e-02,  6.5003e-03, -5.9712e-03,  ...,  3.2641e-01,\n",
            "          3.1142e-01,  1.8561e-01],\n",
            "        [-3.1095e-02, -5.1289e-02, -1.7042e-02,  ...,  3.1142e-01,\n",
            "          9.9256e-02,  1.7180e-01],\n",
            "        [ 3.7020e-02,  5.7730e-02,  1.9428e-02,  ...,  1.8561e-01,\n",
            "          1.7180e-01,  1.0842e-01]], dtype=torch.float64,\n",
            "       grad_fn=<SubBackward0>)\n",
            "tensor([[ 2.6554e-02,  3.0304e-02,  1.5820e-03,  ...,  6.9426e-03,\n",
            "         -2.8926e-02,  6.9095e-02],\n",
            "        [ 3.0304e-02, -1.9596e-01, -5.0506e-02,  ..., -2.6984e-01,\n",
            "          1.0674e-01, -3.2264e-01],\n",
            "        [ 1.5820e-03, -5.0506e-02, -2.7136e-02,  ..., -8.5415e-02,\n",
            "         -4.8283e-03, -7.9199e-02],\n",
            "        ...,\n",
            "        [ 6.9426e-03, -2.6984e-01, -8.5415e-02,  ..., -1.7150e+00,\n",
            "          3.2821e-01, -1.5954e+00],\n",
            "        [-2.8926e-02,  1.0674e-01, -4.8283e-03,  ...,  3.2821e-01,\n",
            "          1.1659e-01,  3.4375e-01],\n",
            "        [ 6.9095e-02, -3.2264e-01, -7.9199e-02,  ..., -1.5954e+00,\n",
            "          3.4375e-01, -1.5148e+00]], dtype=torch.float64,\n",
            "       grad_fn=<SubBackward0>)\n",
            "tensor([[ 3.5052e-03, -3.7316e-03, -5.1296e-04,  ...,  2.7021e-02,\n",
            "          4.1022e-02, -2.1646e-02],\n",
            "        [-3.7316e-03, -2.0348e-02,  2.8173e-03,  ..., -1.8287e-02,\n",
            "          4.2794e-02, -3.4881e-02],\n",
            "        [-5.1296e-04,  2.8173e-03, -5.9274e-03,  ...,  1.3846e-02,\n",
            "         -2.9802e-02,  1.1408e-02],\n",
            "        ...,\n",
            "        [ 2.7021e-02, -1.8287e-02,  1.3846e-02,  ...,  1.2396e-01,\n",
            "          7.5409e-01,  2.2900e-01],\n",
            "        [ 4.1022e-02,  4.2794e-02, -2.9802e-02,  ...,  7.5409e-01,\n",
            "         -3.2420e+00,  1.0431e+00],\n",
            "        [-2.1646e-02, -3.4881e-02,  1.1408e-02,  ...,  2.2900e-01,\n",
            "          1.0431e+00,  4.3025e-01]], dtype=torch.float64,\n",
            "       grad_fn=<SubBackward0>)\n",
            "tensor([[-1.7049e-02,  5.1991e-05, -3.9703e-04,  ...,  9.0761e-03,\n",
            "         -1.8664e-02, -3.4023e-03],\n",
            "        [ 5.1991e-05,  3.9167e-03, -2.8899e-04,  ...,  1.0056e-03,\n",
            "          1.2991e-02, -2.9033e-02],\n",
            "        [-3.9703e-04, -2.8899e-04,  1.7743e-02,  ..., -8.6113e-04,\n",
            "         -1.0605e-02,  6.8205e-02],\n",
            "        ...,\n",
            "        [ 9.0761e-03,  1.0056e-03, -8.6113e-04,  ..., -2.4706e-01,\n",
            "          2.4785e-02, -3.1780e-01],\n",
            "        [-1.8664e-02,  1.2991e-02, -1.0605e-02,  ...,  2.4785e-02,\n",
            "          1.5968e-01,  2.5243e-02],\n",
            "        [-3.4023e-03, -2.9033e-02,  6.8205e-02,  ..., -3.1780e-01,\n",
            "          2.5243e-02, -4.2018e-01]], dtype=torch.float64,\n",
            "       grad_fn=<SubBackward0>)\n",
            "tensor([[-2.2797e-02, -4.2520e-03,  4.4493e-03,  ...,  1.8370e-03,\n",
            "         -3.3076e-02,  5.8649e-02],\n",
            "        [-4.2520e-03, -2.0476e-02,  2.1572e-03,  ...,  4.4361e-02,\n",
            "         -2.3650e-02,  3.9376e-02],\n",
            "        [ 4.4493e-03,  2.1572e-03, -1.1944e-02,  ...,  3.0442e-03,\n",
            "          1.7020e-02, -2.6966e-02],\n",
            "        ...,\n",
            "        [ 1.8370e-03,  4.4361e-02,  3.0442e-03,  ..., -1.9963e+00,\n",
            "          1.0800e+00, -1.4986e+00],\n",
            "        [-3.3076e-02, -2.3650e-02,  1.7020e-02,  ...,  1.0800e+00,\n",
            "          7.2883e-02,  8.1400e-01],\n",
            "        [ 5.8649e-02,  3.9376e-02, -2.6966e-02,  ..., -1.4986e+00,\n",
            "          8.1400e-01, -1.1268e+00]], dtype=torch.float64,\n",
            "       grad_fn=<SubBackward0>)\n",
            "tensor([[-1.7895e-02, -1.5476e-03,  1.3516e-03,  ...,  3.9831e-03,\n",
            "          5.0452e-02, -1.1274e-02],\n",
            "        [-1.5476e-03,  1.3811e-02, -1.1495e-05,  ..., -2.5883e-02,\n",
            "         -1.5387e-02, -1.2361e-03],\n",
            "        [ 1.3516e-03, -1.1495e-05,  2.0297e-03,  ...,  3.3804e-02,\n",
            "          3.1989e-02, -4.4924e-03],\n",
            "        ...,\n",
            "        [ 3.9831e-03, -2.5883e-02,  3.3804e-02,  ..., -1.2704e-01,\n",
            "          9.8848e-02, -8.5514e-02],\n",
            "        [ 5.0452e-02, -1.5387e-02,  3.1989e-02,  ...,  9.8848e-02,\n",
            "          2.1565e-01,  1.0089e-01],\n",
            "        [-1.1274e-02, -1.2361e-03, -4.4924e-03,  ..., -8.5514e-02,\n",
            "          1.0089e-01, -3.7843e-02]], dtype=torch.float64,\n",
            "       grad_fn=<SubBackward0>)\n",
            "tensor([[ 0.0009, -0.0015,  0.0046,  ..., -0.0285,  0.0261, -0.0141],\n",
            "        [-0.0015, -0.0340,  0.0025,  ..., -0.0152,  0.0266, -0.0069],\n",
            "        [ 0.0046,  0.0025, -0.0183,  ...,  0.0426, -0.0473,  0.0090],\n",
            "        ...,\n",
            "        [-0.0285, -0.0152,  0.0426,  ...,  0.0652,  0.5062,  0.0530],\n",
            "        [ 0.0261,  0.0266, -0.0473,  ...,  0.5062, -0.6656,  0.4942],\n",
            "        [-0.0141, -0.0069,  0.0090,  ...,  0.0530,  0.4942,  0.0426]],\n",
            "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "tensor([[ 0.0154, -0.0023, -0.0033,  ..., -0.0023,  0.0245, -0.0159],\n",
            "        [-0.0023,  0.0144,  0.0030,  ...,  0.0120, -0.0485,  0.0185],\n",
            "        [-0.0033,  0.0030,  0.0106,  ..., -0.0240, -0.0148, -0.0259],\n",
            "        ...,\n",
            "        [-0.0023,  0.0120, -0.0240,  ...,  0.4315,  0.1568,  0.3371],\n",
            "        [ 0.0245, -0.0485, -0.0148,  ...,  0.1568, -0.4370,  0.1471],\n",
            "        [-0.0159,  0.0185, -0.0259,  ...,  0.3371,  0.1471,  0.2664]],\n",
            "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "tensor([[-0.0389, -0.0024, -0.0045,  ...,  0.0969, -0.0238,  0.0857],\n",
            "        [-0.0024,  0.0138,  0.0105,  ...,  0.0149,  0.0333, -0.0190],\n",
            "        [-0.0045,  0.0105,  0.0099,  ...,  0.0489,  0.0285, -0.0096],\n",
            "        ...,\n",
            "        [ 0.0969,  0.0149,  0.0489,  ..., -0.6727,  0.3017, -1.1647],\n",
            "        [-0.0238,  0.0333,  0.0285,  ...,  0.3017,  0.3915,  0.5180],\n",
            "        [ 0.0857, -0.0190, -0.0096,  ..., -1.1647,  0.5180, -2.0512]],\n",
            "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "tensor([[ 0.0028,  0.0060,  0.0082,  ..., -0.0292, -0.0043, -0.0110],\n",
            "        [ 0.0060, -0.0154, -0.0023,  ..., -0.0572, -0.0158, -0.1430],\n",
            "        [ 0.0082, -0.0023,  0.0434,  ..., -0.0971, -0.0098, -0.1972],\n",
            "        ...,\n",
            "        [-0.0292, -0.0572, -0.0971,  ..., -1.4307, -0.3368, -1.7532],\n",
            "        [-0.0043, -0.0158, -0.0098,  ..., -0.3368, -0.1057, -0.6007],\n",
            "        [-0.0110, -0.1430, -0.1972,  ..., -1.7532, -0.6007, -2.1980]],\n",
            "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "tensor([[-8.3191e-03,  2.2341e-04, -2.0608e-03,  ..., -2.5208e-02,\n",
            "          2.2360e-02, -2.1378e-02],\n",
            "        [ 2.2341e-04, -4.0103e-02, -7.1726e-03,  ...,  3.6574e-02,\n",
            "         -9.4582e-02,  6.4534e-02],\n",
            "        [-2.0608e-03, -7.1726e-03, -1.7665e-02,  ..., -1.6815e-03,\n",
            "         -2.1663e-02,  3.3939e-03],\n",
            "        ...,\n",
            "        [-2.5208e-02,  3.6574e-02, -1.6815e-03,  ...,  3.0366e-01,\n",
            "          7.0335e-01,  1.8569e-01],\n",
            "        [ 2.2360e-02, -9.4582e-02, -2.1663e-02,  ...,  7.0335e-01,\n",
            "         -4.1010e-01,  3.7117e-01],\n",
            "        [-2.1378e-02,  6.4534e-02,  3.3939e-03,  ...,  1.8569e-01,\n",
            "          3.7117e-01,  1.1479e-01]], dtype=torch.float64,\n",
            "       grad_fn=<SubBackward0>)\n",
            "tensor([[-0.0060,  0.0027,  0.0018,  ..., -0.0452, -0.0044, -0.0042],\n",
            "        [ 0.0027, -0.0021, -0.0057,  ...,  0.0348,  0.0237,  0.0019],\n",
            "        [ 0.0018, -0.0057,  0.0156,  ...,  0.0294, -0.0131,  0.0793],\n",
            "        ...,\n",
            "        [-0.0452,  0.0348,  0.0294,  ..., -1.2243, -0.2146, -0.9943],\n",
            "        [-0.0044,  0.0237, -0.0131,  ..., -0.2146,  0.0890, -0.1680],\n",
            "        [-0.0042,  0.0019,  0.0793,  ..., -0.9943, -0.1680, -0.8319]],\n",
            "       dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "tensor([[-2.5178e-02, -4.9081e-05,  1.6993e-03,  ..., -6.0316e-02,\n",
            "          1.5764e-02, -2.9094e-02],\n",
            "        [-4.9081e-05, -1.6048e-02, -1.3563e-04,  ...,  6.1098e-03,\n",
            "         -5.2839e-03,  8.9806e-03],\n",
            "        [ 1.6993e-03, -1.3563e-04,  7.7526e-03,  ..., -4.4039e-02,\n",
            "         -1.1884e-02,  2.5273e-03],\n",
            "        ...,\n",
            "        [-6.0316e-02,  6.1098e-03, -4.4039e-02,  ...,  2.5458e-01,\n",
            "          2.3649e-01,  2.1966e-01],\n",
            "        [ 1.5764e-02, -5.2839e-03, -1.1884e-02,  ...,  2.3649e-01,\n",
            "         -3.0427e-01,  1.7917e-01],\n",
            "        [-2.9094e-02,  8.9806e-03,  2.5273e-03,  ...,  2.1966e-01,\n",
            "          1.7917e-01,  1.7903e-01]], dtype=torch.float64,\n",
            "       grad_fn=<SubBackward0>)\n",
            "tensor([[-2.9146e-02, -1.6144e-03, -1.1446e-04,  ...,  2.4603e-02,\n",
            "          2.3024e-02,  4.1898e-04],\n",
            "        [-1.6144e-03, -6.0047e-03, -1.0900e-03,  ..., -4.6563e-02,\n",
            "         -3.3369e-02,  2.6534e-02],\n",
            "        [-1.1446e-04, -1.0900e-03,  1.9500e-03,  ..., -2.3603e-02,\n",
            "          6.0851e-03, -7.9477e-03],\n",
            "        ...,\n",
            "        [ 2.4603e-02, -4.6563e-02, -2.3603e-02,  ..., -7.5740e-01,\n",
            "          5.6861e-01, -6.8918e-01],\n",
            "        [ 2.3024e-02, -3.3369e-02,  6.0851e-03,  ...,  5.6861e-01,\n",
            "          1.2225e-01,  4.8147e-01],\n",
            "        [ 4.1898e-04,  2.6534e-02, -7.9477e-03,  ..., -6.8918e-01,\n",
            "          4.8147e-01, -6.0574e-01]], dtype=torch.float64,\n",
            "       grad_fn=<SubBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-04a1c787b84d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFisher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_avg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_avg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mFisher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0mall_fishers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFisher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-e8cbf07a1ff1>\u001b[0m in \u001b[0;36mhessian\u001b[0;34m(y, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfisher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-e8cbf07a1ff1>\u001b[0m in \u001b[0;36mjacobian\u001b[0;34m(y, x, create_graph)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mgrad_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mgrad_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mjac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mgrad_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    202\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    203\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhMzalOD8-Y9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42afba08-7dfb-46a6-9825-901c491d3f66"
      },
      "source": [
        "!pip install pennylane"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pennylane\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/f9/d3594cf0335d0fb3ec72947bbc6db204f1332588463bb5b9b43083ea35c9/PennyLane-0.14.1.tar.gz (404kB)\n",
            "\r\u001b[K     |▉                               | 10kB 21.7MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20kB 18.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30kB 11.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 40kB 9.3MB/s eta 0:00:01\r\u001b[K     |████                            | 51kB 7.7MB/s eta 0:00:01\r\u001b[K     |████▉                           | 61kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 71kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 81kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 92kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 102kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 112kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 122kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 133kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 143kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 153kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 163kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 174kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 184kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 194kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 204kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 215kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 225kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 235kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 245kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 256kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 266kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 276kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 286kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 296kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 307kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 317kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 327kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 337kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 348kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 358kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 368kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 378kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 389kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 399kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 409kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from pennylane) (2.5)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.3)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.4.4)\n",
            "Collecting semantic_version==2.6\n",
            "  Downloading https://files.pythonhosted.org/packages/28/be/3a7241d731ba89063780279a5433f5971c1cf41735b64a9f874b7c3ff995/semantic_version-2.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx->pennylane) (4.4.2)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd->pennylane) (0.16.0)\n",
            "Building wheels for collected packages: pennylane\n",
            "  Building wheel for pennylane (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pennylane: filename=PennyLane-0.14.1-cp37-none-any.whl size=481980 sha256=b44504ce62d99a8b69b745c70de29561e8f7c3e15ca8530d27b7c4e17dbc4d3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/a9/c9/04941d6dd58b3c111cbd1389bf63ba1b23362c137359af4626\n",
            "Successfully built pennylane\n",
            "Installing collected packages: semantic-version, pennylane\n",
            "Successfully installed pennylane-0.14.1 semantic-version-2.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCJ-RTKBaELE"
      },
      "source": [
        "import pennylane as qml\r\n",
        "from pennylane import numpy as np\r\n",
        "import copy\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl2E-_npblT5"
      },
      "source": [
        "n_samples = 100\r\n",
        "variance = (np.pi/4)**2\r\n",
        "X0 = np.array([[np.random.normal(loc=-np.pi/4, scale=variance), \r\n",
        "                np.random.normal(loc=np.pi/4, scale=variance),\r\n",
        "                np.random.normal(loc=-np.pi/4, scale=variance),\r\n",
        "                np.random.normal(loc=np.pi/4, scale=variance)] for i in range(int(n_samples/2))],requires_grad=False)\r\n",
        "\r\n",
        "\r\n",
        "X1 = np.array([[np.random.normal(loc=np.pi/4, scale=variance), \r\n",
        "                np.random.normal(loc=-np.pi/4, scale=variance),\r\n",
        "                np.random.normal(loc=np.pi/4, scale=variance),\r\n",
        "                np.random.normal(loc=-np.pi/4, scale=variance)] for i in range(int(n_samples/2))],requires_grad=False)\r\n",
        "\r\n",
        "X = np.append(X0, X1,0)\r\n",
        "\r\n",
        "Y = np.append(np.array([0 for i in range(int(n_samples/2))],requires_grad=False),np.array([1 for i in range(int(n_samples/2))],requires_grad=False))\r\n",
        "\r\n",
        "data = list(zip(X, Y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7hit-dmfEod",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a785f5c9-a716-4aba-e85c-479dc0224fe0"
      },
      "source": [
        "depth=15\r\n",
        "\r\n",
        "dev = qml.device(\"default.qubit\", wires=5)\r\n",
        "@qml.qnode(dev, diff_method='backprop', wires=5)\r\n",
        "def quantum_neural_network(x, w, depth):\r\n",
        "\r\n",
        "    #encoding circuit============================================================\r\n",
        "\r\n",
        "    #Hadamards\r\n",
        "    for i in range(4):\r\n",
        "        qml.Hadamard(wires=i)\r\n",
        "        \r\n",
        "    #Accounting for depth=0\r\n",
        "    if(depth==0):\r\n",
        "        for i in range(4):\r\n",
        "            qml.RZ(x[i],wires=i)\r\n",
        "\r\n",
        "    #Multiple encoding layers:\r\n",
        "    for k in range(depth):\r\n",
        "        #RZ gates\r\n",
        "        for i in range(4):\r\n",
        "            qml.RZ(x[i],wires=i)\r\n",
        "        #RZZ gates\r\n",
        "        for i in range(4):\r\n",
        "            for j in range(i):\r\n",
        "                qml.CNOT(wires=[j,i])\r\n",
        "                qml.RZ(((x[i])*(x[j])),wires=[i])\r\n",
        "                qml.CNOT(wires=[j,i])\r\n",
        "\r\n",
        "        \r\n",
        "    #variational circuit\r\n",
        "    for j in range(9):\r\n",
        "      for i in range(4):\r\n",
        "          qml.RY(w[j][i],wires=i)\r\n",
        "      qml.broadcast(qml.CNOT, wires=[0,1,2,3], pattern=\"all_to_all\", parameters=None, kwargs=None)\r\n",
        "\r\n",
        "    for i in range(4):\r\n",
        "        qml.RY(w[9][i],wires=i)\r\n",
        "\r\n",
        "    dev.shots = 1000\r\n",
        "    \r\n",
        "    for i in range(4):\r\n",
        "      qml.CNOT(wires=[i,4])\r\n",
        "    \r\n",
        "    return qml.expval(qml.PauliZ(wires=4))\r\n",
        "\r\n",
        "\r\n",
        " \r\n",
        "@qml.qnode(dev, diff_method='backprop', wires=5)\r\n",
        "def easy_quantum(x, w):\r\n",
        "  #encoding\r\n",
        "    for i in range(4):\r\n",
        "      qml.Hadamard(wires=[i])\r\n",
        "      qml.RZ(x[i],wires=i)\r\n",
        "    \r\n",
        "\r\n",
        "    #variational circuit\r\n",
        "    for j in range(9):\r\n",
        "      for i in range(4):\r\n",
        "          qml.RY(w[j][i],wires=i)\r\n",
        "      qml.broadcast(qml.CNOT, wires=[0,1,2,3], pattern=\"all_to_all\", parameters=None, kwargs=None)\r\n",
        "    for i in range(4):\r\n",
        "        qml.RY(w[9][i],wires=i)\r\n",
        "\r\n",
        "    dev.shots = 1000\r\n",
        "    for i in range(4):\r\n",
        "      qml.CNOT(wires=[i,4])\r\n",
        "    \r\n",
        "    return qml.expval(qml.PauliZ(wires=4))\r\n",
        "\r\n",
        "\r\n",
        "def get_parity_prediction(model, x,w):\r\n",
        "\r\n",
        "    #choice of models\r\n",
        "    if model==\"QNN\": np_measurements = (quantum_neural_network(x,w)+1.)/2.\r\n",
        "    else: np_measurements= (easy_quantum(x,w)+1.)/2.\r\n",
        "  \r\n",
        "    return np.array([np_measurements,1.-np_measurements])\r\n",
        "\r\n",
        "def single_loss(model, w,x,y):\r\n",
        "    prediction = get_parity_prediction(model, x,w)\r\n",
        "    return rel_ent(prediction, y)\r\n",
        "\r\n",
        "def rel_ent(pred,y):\r\n",
        "    return -np.log(pred)[int(y)]\r\n",
        "\r\n",
        "def average_loss(w, data,model):\r\n",
        "  c = 0\r\n",
        "  Fisher = np.zeros((40,40))\r\n",
        "  for i,(x, y) in enumerate(data):\r\n",
        "    single_cost = single_loss(model,w,x,y)\r\n",
        "    \r\n",
        "    c += single_cost\r\n",
        "    grad_fn = qml.grad(single_loss,argnum=1)\r\n",
        "    gradient = grad_fn(model,w,x,y).flatten()\r\n",
        "    Fisher += np.outer(gradient,gradient)\r\n",
        "  \r\n",
        "  return c/len(data),Fisher/len(data)\r\n",
        "\r\n",
        "EVs = np.array([])\r\n",
        "models=[\"QNN\"]\r\n",
        "n_iter=5\r\n",
        "all_fishers = np.zeros((2,n_iter,40,40))\r\n",
        "count = 0\r\n",
        "for i in range(n_iter):\r\n",
        "  print(i)\r\n",
        "  for j, model in enumerate(models):\r\n",
        "    w = np.array(np.split(np.random.uniform(size=(40,),low=-1.0,high=1.0),10),requires_grad=True)\r\n",
        "    Fisher = average_loss(w,data,model)[1]\r\n",
        "    all_fishers[j][i]=Fisher\r\n",
        "\r\n",
        "def normalise_fishers(Fishers):\r\n",
        "    num_samples = len(Fishers)\r\n",
        "    TrF_integral = (1 / num_samples) * np.sum([np.trace(F) for F in Fishers])\r\n",
        "    return [((40) / TrF_integral) * F for F in Fishers]\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "[[[ 5.90638025e-02  2.45610398e-02  5.84173259e-02  1.10941570e-01]\n",
            "  [-3.21551138e-02  6.74661749e-02  5.24559679e-02 -1.03978967e-01]\n",
            "  [ 4.05158882e-02  6.48490713e-02 -1.16242809e-01 -4.71392621e-02]\n",
            "  [-9.65968048e-02 -4.11786255e-02  5.04265494e-02 -2.04032048e-02]\n",
            "  [-5.53361586e-02  5.16904908e-02  4.89509375e-02  2.63897784e-02]\n",
            "  [ 4.72206740e-02  1.21947335e-01 -6.19153100e-03 -2.98855656e-02]\n",
            "  [-1.44259970e-02  4.28402062e-02 -2.62159224e-02 -3.92976980e-02]\n",
            "  [ 4.85956741e-03 -1.60925319e-04 -4.09059439e-02 -8.12602989e-02]\n",
            "  [-1.89757369e-02 -3.42398211e-02 -3.62464029e-02  6.16256577e-03]\n",
            "  [-1.66033216e-01  1.22650844e-01 -8.46026933e-02  2.07999586e-02]]\n",
            "\n",
            " [[-5.90638025e-02 -2.45610398e-02 -5.84173259e-02 -1.10941570e-01]\n",
            "  [ 3.21551138e-02 -6.74661749e-02 -5.24559679e-02  1.03978967e-01]\n",
            "  [-4.05158882e-02 -6.48490713e-02  1.16242809e-01  4.71392621e-02]\n",
            "  [ 9.65968048e-02  4.11786255e-02 -5.04265494e-02  2.04032048e-02]\n",
            "  [ 5.53361586e-02 -5.16904908e-02 -4.89509375e-02 -2.63897784e-02]\n",
            "  [-4.72206740e-02 -1.21947335e-01  6.19153100e-03  2.98855656e-02]\n",
            "  [ 1.44259970e-02 -4.28402062e-02  2.62159224e-02  3.92976980e-02]\n",
            "  [-4.85956741e-03  1.60925319e-04  4.09059439e-02  8.12602989e-02]\n",
            "  [ 1.89757369e-02  3.42398211e-02  3.62464029e-02 -6.16256577e-03]\n",
            "  [ 1.66033216e-01 -1.22650844e-01  8.46026933e-02 -2.07999586e-02]]]\n",
            "[[[ 5.90638025e-02 -5.90638025e-02]\n",
            "  [-3.21551138e-02  3.21551138e-02]\n",
            "  [ 4.05158882e-02 -4.05158882e-02]\n",
            "  [-9.65968048e-02  9.65968048e-02]\n",
            "  [-5.53361586e-02  5.53361586e-02]\n",
            "  [ 4.72206740e-02 -4.72206740e-02]\n",
            "  [-1.44259970e-02  1.44259970e-02]\n",
            "  [ 4.85956741e-03 -4.85956741e-03]\n",
            "  [-1.89757369e-02  1.89757369e-02]\n",
            "  [-1.66033216e-01  1.66033216e-01]]\n",
            "\n",
            " [[ 2.45610398e-02 -2.45610398e-02]\n",
            "  [ 6.74661749e-02 -6.74661749e-02]\n",
            "  [ 6.48490713e-02 -6.48490713e-02]\n",
            "  [-4.11786255e-02  4.11786255e-02]\n",
            "  [ 5.16904908e-02 -5.16904908e-02]\n",
            "  [ 1.21947335e-01 -1.21947335e-01]\n",
            "  [ 4.28402062e-02 -4.28402062e-02]\n",
            "  [-1.60925319e-04  1.60925319e-04]\n",
            "  [-3.42398211e-02  3.42398211e-02]\n",
            "  [ 1.22650844e-01 -1.22650844e-01]]\n",
            "\n",
            " [[ 5.84173259e-02 -5.84173259e-02]\n",
            "  [ 5.24559679e-02 -5.24559679e-02]\n",
            "  [-1.16242809e-01  1.16242809e-01]\n",
            "  [ 5.04265494e-02 -5.04265494e-02]\n",
            "  [ 4.89509375e-02 -4.89509375e-02]\n",
            "  [-6.19153100e-03  6.19153100e-03]\n",
            "  [-2.62159224e-02  2.62159224e-02]\n",
            "  [-4.09059439e-02  4.09059439e-02]\n",
            "  [-3.62464029e-02  3.62464029e-02]\n",
            "  [-8.46026933e-02  8.46026933e-02]]\n",
            "\n",
            " [[ 1.10941570e-01 -1.10941570e-01]\n",
            "  [-1.03978967e-01  1.03978967e-01]\n",
            "  [-4.71392621e-02  4.71392621e-02]\n",
            "  [-2.04032048e-02  2.04032048e-02]\n",
            "  [ 2.63897784e-02 -2.63897784e-02]\n",
            "  [-2.98855656e-02  2.98855656e-02]\n",
            "  [-3.92976980e-02  3.92976980e-02]\n",
            "  [-8.12602989e-02  8.12602989e-02]\n",
            "  [ 6.16256577e-03 -6.16256577e-03]\n",
            "  [ 2.07999586e-02 -2.07999586e-02]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-4094541abe64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mFisher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0mall_fishers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFisher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-4094541abe64>\u001b[0m in \u001b[0;36maverage_loss\u001b[0;34m(w, data, model)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mjac_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjac_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mFisher\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjac_T\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiag_pi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpi_n_pi_n_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFisher\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/numpy/wrapper.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# evaluate the original object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_autograd_primitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/numpy/tensor.py\u001b[0m in \u001b[0;36m__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# call the ndarray.__array_ufunc__ method to compute the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# of the vectorized ufunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_ufunc__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 10 is different from 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTJ6b8V9rONW"
      },
      "source": [
        "#all_fishers = np.load(\"fisher.npy\")\r\n",
        "def normalise_fishers(Fishers):\r\n",
        "    num_samples = len(Fishers)\r\n",
        "    TrF_integral = (1. / num_samples) * np.sum([np.trace(F) for F in Fishers])\r\n",
        "    return [((40) / TrF_integral) * F for F in Fishers]\r\n",
        "\r\n",
        "def get_entropy(x,length):\r\n",
        "  entropy=0\r\n",
        "  x = x/length\r\n",
        "  for i in x:\r\n",
        "    if(i!=0):\r\n",
        "      entropy-=i*np.log(i)\r\n",
        "  return entropy\r\n",
        "\r\n",
        "normalised_fishers = normalise_fishers(all_fishers[0])\r\n",
        "EVs = np.array([])\r\n",
        "for F in normalised_fishers:\r\n",
        "  val, v = np.linalg.eig(F)\r\n",
        "  EVs = np.append(np.real(EVs),val)\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "tkAa8q5Insu8",
        "outputId": "fac4f840-a54e-45e2-ddb1-91580850d7b0"
      },
      "source": [
        "\r\n",
        "#plot histogram\r\n",
        "x, bins, p=plt.hist(EVs, bins=10,rwidth=0.6,color='black')\r\n",
        "\r\n",
        "for item in p:\r\n",
        "  item.set_height(item.get_height()/len(EVs)) # normalise it\r\n",
        "plt.ylim(0,1)\r\n",
        "plt.title(\"QNN - RYRX normalised\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4Kr1c5HNnCl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8d88868-7dc0-4556-c7c8-477e71ef3ed3"
      },
      "source": [
        "get_entropy(x,len(EVs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.552223372523677"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjfRqVDwE1t_"
      },
      "source": [
        "Easy Quantum using backprop\r\n",
        "![EQ - backprop.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAX8AAAEICAYAAAC3Y/QeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPeElEQVR4nO3de4xcZ3nH8e8PmyQtl6SQ5VLbYEOMwCAq6CqgUtGogJoY1aY3sCV6oQFLgGkFqJURbUCuKiVEApUSlBqRUhCNY6DQrWIaFQqiUBK8lEsTR4bFpMSBNk64VCmF4PL0jz1G482ud+I9M+P4/X6kUc55zzvvPE/W+e3xOTOTVBWSpLY8aNIFSJLGz/CXpAYZ/pLUIMNfkhpk+EtSgwx/SWqQ4S9JDTL8JalBhr+alOS2JP+b5J6Bxzu6Y2uTvD/J3Un+J8nnkmyedM1Snwx/texXq+qhA4+dSR4BfBq4F3gqcD7wNmBvkhdNslipT6snXYB0mnktcA9waVX9uBu7NsnjgLcm+fvyO1F0BvDMXzrRC4APDQT/cfuADcAF4y9J6p/hr5Z9JMl3Bx6vYP4yz7cWmXt8bGp85Umj42UftexFVfWxwYEklwKPXWTu8bG7Rl6VNAae+Usn+hjw60kW/rfxYuAIMDf+kqT+Gf7Sid4GnAu8O8ljkpyTZDvwp8CbFrkXID0gGf5q2T8seJ//h6vqbuAXgXOAg8y/8+e9wKur6ppJFiv1yWv+alJVrT/JsW8A2wGSPBz4DPDE8VQmjceyZ/5JrklyZ5KblzieJG9PMpfky0me2X+Z0mRU1X8Dm4H/S/KYSdcj9SXLfV4lyXPp/upbVU9b5Phm4DXM/wfyLOAvqupZI6hVktSTZc/8q+pTwLdPMmUr878YqqpuBM5Lsthb5SRJp4k+rvmvAW4f2D/Sjd3ngzJJdgA7AB7ykIf8/JOf/OQeXl6S2vH5z3/+rqpa8YcNx3rDt6r2AHsApqena3Z2dpwvL0kPeEn+o491+nir5x3AuoH9td2YJOk01Uf4zwC/073r59nA96pqse9GkSSdJpa97JPkWuAi4PwkR4A3AQ8GqKqrgf3Mv9NnDvg+8LJRFStJ6sey4V9V25c5XsCre6tIkjRyfr2DJDXI8JekBhn+ktQgw1+SGmT4S1KDDH9JapDhL0kNMvwlqUGGvyQ1yPCXpAYZ/pLUoAfk/8B9/a7rJ/bat13+wom9tiT1xTN/SWqQ4S9JDTL8JalBhr8kNcjwl6QGGf6S1CDDX5IaZPhLUoMMf0lqkOEvSQ0y/CWpQYa/JDXI8JekBhn+ktQgw1+SGmT4S1KDDH9JapDhL0kNMvwlqUGGvyQ1yPCXpAYZ/pLUIMNfkho0VPgnuTjJoSRzSXYtcvxxST6R5AtJvpxkc/+lSpL6smz4J1kFXAVcAmwCtifZtGDanwD7quoZwDbgnX0XKknqzzBn/hcCc1V1uKruBfYCWxfMKeDh3fa5wDf7K1GS1Ldhwn8NcPvA/pFubNCbgZcmOQLsB16z2EJJdiSZTTJ79OjRUyhXktSHvm74bgfeU1Vrgc3A+5LcZ+2q2lNV01U1PTU11dNLS5Lur2HC/w5g3cD+2m5s0KXAPoCq+ixwDnB+HwVKkvo3TPgfADYm2ZDkLOZv6M4smPMN4HkASZ7CfPh7XUeSTlPLhn9VHQN2AjcAtzL/rp5bkuxOsqWb9nrgFUm+BFwL/F5V1aiKliStzOphJlXVfuZv5A6OXTawfRB4Tr+lSZJGxU/4SlKDDH9JapDhL0kNMvwlqUGGvyQ1yPCXpAYZ/pLUIMNfkhpk+EtSgwx/SWqQ4S9JDTL8JalBhr8kNcjwl6QGGf6S1CDDX5IaZPhLUoMMf0lqkOEvSQ0y/CWpQYa/JDXI8JekBhn+ktQgw1+SGmT4S1KDDH9JapDhL0kNMvwlqUGGvyQ1yPCXpAYZ/pLUIMNfkhpk+EtSgwx/SWrQUOGf5OIkh5LMJdm1xJwXJzmY5JYkf9tvmZKkPq1ebkKSVcBVwAuAI8CBJDNVdXBgzkbgDcBzquo7SR41qoIlSSs3zJn/hcBcVR2uqnuBvcDWBXNeAVxVVd8BqKo7+y1TktSnYcJ/DXD7wP6RbmzQk4AnJflMkhuTXLzYQkl2JJlNMnv06NFTq1iStGJ93fBdDWwELgK2A+9Kct7CSVW1p6qmq2p6amqqp5eWJN1fw4T/HcC6gf213digI8BMVf2oqr4OfIX5XwaSpNPQMOF/ANiYZEOSs4BtwMyCOR9h/qyfJOczfxnocI91SpJ6tGz4V9UxYCdwA3ArsK+qbkmyO8mWbtoNwN1JDgKfAP6oqu4eVdGSpJVZ9q2eAFW1H9i/YOyyge0CXtc9JEmnOT/hK0kNMvwlqUGGvyQ1yPCXpAYZ/pLUIMNfkhpk+EtSgwx/SWqQ4S9JDTL8JalBhr8kNcjwl6QGGf6S1CDDX5IaZPhLUoMMf0lqkOEvSQ0y/CWpQYa/JDXI8JekBhn+ktQgw1+SGmT4S1KDDH9JapDhL0kNMvwlqUGGvyQ1yPCXpAYZ/pLUIMNfkhpk+EtSgwx/SWqQ4S9JDTL8JalBhr8kNWio8E9ycZJDSeaS7DrJvN9IUkmm+ytRktS3ZcM/ySrgKuASYBOwPcmmReY9DPhD4Ka+i5Qk9WuYM/8LgbmqOlxV9wJ7ga2LzPsz4ArgBz3WJ0kagWHCfw1w+8D+kW7sJ5I8E1hXVdefbKEkO5LMJpk9evTo/S5WktSPFd/wTfIg4K3A65ebW1V7qmq6qqanpqZW+tKSpFM0TPjfAawb2F/bjR33MOBpwCeT3AY8G5jxpq8knb6GCf8DwMYkG5KcBWwDZo4frKrvVdX5VbW+qtYDNwJbqmp2JBVLklZs2fCvqmPATuAG4FZgX1XdkmR3ki2jLlCS1L/Vw0yqqv3A/gVjly0x96KVlyVJGiU/4StJDTL8JalBhr8kNcjwl6QGGf6S1CDDX5IaZPhLUoMMf0lqkOEvSQ0y/CWpQYa/JDXI8JekBhn+ktQgw1+SGmT4S1KDDH9JapDhL0kNMvwlqUGGvyQ1yPCXpAYZ/pLUIMNfkhpk+EtSgwx/SWqQ4S9JDTL8JalBhr8kNcjwl6QGGf6S1CDDX5IaZPhLUoMMf0lqkOEvSQ0y/CWpQUOFf5KLkxxKMpdk1yLHX5fkYJIvJ/l4ksf3X6okqS/Lhn+SVcBVwCXAJmB7kk0Lpn0BmK6qpwMfBN7Sd6GSpP4Mc+Z/ITBXVYer6l5gL7B1cEJVfaKqvt/t3gis7bdMSVKfhgn/NcDtA/tHurGlXAp8dLEDSXYkmU0ye/To0eGrlCT1qtcbvkleCkwDVy52vKr2VNV0VU1PTU31+dKSpPth9RBz7gDWDeyv7cZOkOT5wBuBX6qqH/ZTniRpFIY58z8AbEyyIclZwDZgZnBCkmcAfwVsqao7+y9TktSnZcO/qo4BO4EbgFuBfVV1S5LdSbZ0064EHgp8IMkXk8wssZwk6TQwzGUfqmo/sH/B2GUD28/vuS5J0gj5CV9JapDhL0kNMvwlqUGGvyQ1yPCXpAYZ/pLUIMNfkhpk+EtSgwx/SWqQ4S9JDTL8JalBhr8kNcjwl6QGGf6S1CDDX5IaZPhLUoMMf0lqkOEvSQ0y/CWpQYa/JDXI8JekBhn+ktQgw1+SGmT4S1KDDH9JapDhL0kNMvwlqUGGvyQ1yPCXpAatnnQBDzTrd10/kde97fIXTuR1JZ2ZPPOXpAYZ/pLUIMNfkhpk+EtSgwx/SWrQUOGf5OIkh5LMJdm1yPGzk1zXHb8pyfq+C5Uk9WfZt3omWQVcBbwAOAIcSDJTVQcHpl0KfKeqLkiyDbgCeMkoCm7VpN5iCr7NVDoTDfM+/wuBuao6DJBkL7AVGAz/rcCbu+0PAu9IkqqqHmvVhLT22YZJ/qJVG06HE6phwn8NcPvA/hHgWUvNqapjSb4HPBK4a3BSkh3Ajm73niSHTqVo4PyFazekmd5zxX2Gmul9gVb7hjO090X+bC9mqd4f30cNY/2Eb1XtAfasdJ0ks1U13UNJDzj23l7vrfYN9j7K3oe54XsHsG5gf203tuicJKuBc4G7+yhQktS/YcL/ALAxyYYkZwHbgJkFc2aA3+22fxP4Z6/3S9Lpa9nLPt01/J3ADcAq4JqquiXJbmC2qmaAdwPvSzIHfJv5XxCjtOJLRw9g9t6eVvsGex+ZeIIuSe3xE76S1CDDX5IaNLHwX8lXRiR5Qzd+KMmvLLdmd7P6pm78uu7G9USMue/3d+M3J7kmyYNH3d/JjLP3geNvT3LPqHoa1ph/7kny50m+kuTWJH8w6v6WMua+n5fk35J8Mcmnk1ww6v5OZkS9X5PkziQ3L1jrEUn+KclXu3/+zLIFVtXYH8zfOP4a8ATgLOBLwKYFc14FXN1tbwOu67Y3dfPPBjZ066w62ZrAPmBbt3018MpG+t4MpHtcO6m+J9F797xp4H3APZPqe0I/95cB7wUe1O0/qpG+vwI8ZWDd95xJP/Pu2HOBZwI3L1jrLcCubnsXcMVyNU7qzP8nXxlRVfcCx78yYtBW4G+67Q8Cz0uSbnxvVf2wqr4OzHXrLbpm95xf7tagW/NFI+ztZMbWN0BV7a8O8DnmP6MxKWPtPfPfSXUl8Mcj7msYY+0deCWwu6p+DFBVd46wt5MZd98FPLzbPhf45oj6GsYoeqeqPsX8OyoXGlxrqIybVPgv9pURa5aaU1XHgONfGbHUc5cafyTw3W6NpV5rXMbZ9090l3t+G/jHFXdw6sbd+05gpqq+1VP9KzHu3p8IvCTJbJKPJtnYUx/317j7fjmwP8kR5v+8X95LF6dmFL2fzKMH/qz/J/Do5Qr0hm8b3gl8qqr+ZdKFjEOSnwV+C/jLSdcyIWcDP6j5rwZ4F3DNhOsZl9cCm6tqLfDXwFsnXM9EdH/TX/Y9/JMK/5V8ZcRSz11q/G7gvG6NpV5rXMbZN90abwKmgNf10sGpG2fvzwAuAOaS3Ab8dOY/gDgp4/65HwH+rtv+MPD0FXdwasbWd5Ip4Oeq6qZu/DrgF/pp45SMoveT+a8kj+3Weiyw/KW+Cd0MWQ0cZv5mxvGbIU9dMOfVnHgzZF+3/VROvBlymPmbK0uuCXyAE2/4vqqRvl8O/CvwU5Pod5K9L1h30jd8x/1zvxz4/W77IuDAmd53N34X8KTu+ZcCHzqTfuYDz1vPfW/4XsmJN3zfsmyNE/yXs5n5u/NfA97Yje0GtnTb5zAf2nPM36x8wsBz39g97xBwycnW7Maf0K0x1615diN9H+vGvtg9LptU3+PufcHrTjT8J/BzPw+4Hvh34LPMnxG30PevdT1/Cfjk4FpnUO/XAt8CfsT83/Au7cYfCXwc+CrwMeARy9Xn1ztIUoO84StJDTL8JalBhr8kNcjwl6QGGf6S1CDDX5IaZPhLUoP+H8jQeR650V0RAAAAAElFTkSuQmCC)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "Easy Quantum using Parameter Shift\r\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TsBiiSNZH4m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "49c944c2-699e-4904-c170-9390f806184f"
      },
      "source": [
        "entropies=np.array([0.439,0.545,1.162,1.274,1.307,1.476,1.572,1.588,1.633,1.572,1.723,1.606,1.309,1.697,1.566])\r\n",
        "plt.plot(range(depth+1),entropies, 'bo')\r\n",
        "plt.title(\"avg normalised Fisher spectrum entropy vs encoding depth\")\r\n",
        "plt.xlabel(\"encoding depth\")\r\n",
        "plt.ylabel(\"entropy (10 bins)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'entropy (10 bins)')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyL8-y98-i29",
        "outputId": "69f4f616-db3d-48a6-f7d1-4d32a53fe25d"
      },
      "source": [
        "len(data)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emW05-xj8K66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4cd00151-f502-4f98-e753-817e30607f2d"
      },
      "source": [
        "models[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'EQ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "S1m9OTI3aMv1",
        "outputId": "4259b750-070b-4b16-e2b7-6236066228c7"
      },
      "source": [
        "n_samples = 100\r\n",
        "variance = 1\r\n",
        "X0 =np.array([[np.random.normal(loc=-1, scale=variance), \r\n",
        "                np.random.normal(loc=1, scale=variance),\r\n",
        "                np.random.normal(loc=-1, scale=variance),\r\n",
        "                np.random.normal(loc=1, scale=variance)] for i in range(int(n_samples/2))],requires_grad=False)\r\n",
        "\r\n",
        "\r\n",
        "X1 = np.array([[np.random.normal(loc=1, scale=variance), \r\n",
        "                np.random.normal(loc=-1, scale=variance),\r\n",
        "                np.random.normal(loc=1, scale=variance),\r\n",
        "                np.random.normal(loc=-1, scale=variance)] for i in range(int(n_samples/2))],requires_grad=False)\r\n",
        "\r\n",
        "X = np.append(X0, X1,0)\r\n",
        "\r\n",
        "Y = np.append(np.array([0 for i in range(int(n_samples/2))],requires_grad=False),np.array([1 for i in range(int(n_samples/2))],requires_grad=False))\r\n",
        "\r\n",
        "data = list(zip(X, Y))\r\n",
        "\r\n",
        "dev = qml.device(\"default.qubit\", wires=4) \r\n",
        "@qml.qnode(dev, diff_method='parameter-shift')\r\n",
        "def quantum_neural_network(x, w):\r\n",
        "    qml.templates.IQPEmbedding(x, wires=[0,1,2,3], n_repeats=2, pattern=None)\r\n",
        "    for j in range(10):\r\n",
        "      for i in range(4):\r\n",
        "        qml.RY(w[j][i],wires=i) \r\n",
        "      qml.broadcast(qml.CNOT, wires=[0,1,2,3], pattern=\"all_to_all\", parameters=None, kwargs=None)\r\n",
        "    dev.shots = 1000\r\n",
        "    sample_measurements = [qml.sample(qml.PauliZ(wires=i)) for i in range(4)]\r\n",
        "    return sample_measurements\r\n",
        "\r\n",
        "\r\n",
        "dev = qml.device(\"default.qubit\", wires=4) \r\n",
        "@qml.qnode(dev, diff_method='backprop')\r\n",
        "def easy_quantum(x, w):\r\n",
        "    qml.templates.IQPEmbedding(x, wires=[0,1,2,3], n_repeats=2, pattern=None)\r\n",
        "\r\n",
        "    for j in range(10):\r\n",
        "      for i in range(4):\r\n",
        "        qml.RY(w[j][i],wires=[i]) \r\n",
        "    dev.shots = 1000\r\n",
        "    sample_measurements = [qml.sample(qml.PauliZ(wires=i)) for i in range(4)]\r\n",
        "    return sample_measurements\r\n",
        "\r\n",
        "\r\n",
        "def get_parity_prediction(model, x,w):\r\n",
        "\r\n",
        "    #choice of models\r\n",
        "    if model==\"QNN\": np_measurements = (quantum_neural_network(x,w)+1.)/2.\r\n",
        "    else: np_measurements= (easy_quantum(x,w)+1.)/2.\r\n",
        "    p_1 = (1.-np_measurements).prod() + np_measurements.prod()\r\n",
        "    #get parity\r\n",
        "    for i in range(4):\r\n",
        "        for j in range(i):\r\n",
        "            a = np.zeros((4))\r\n",
        "            a[i] = 1\r\n",
        "            a[j] = 1\r\n",
        "            p_1 += (a-np_measurements).prod()\r\n",
        "    return np.array([p_1,1.-p_1])\r\n",
        "\r\n",
        "def rel_ent(pred,y):\r\n",
        "    return -1.*np.log(pred)[int(y)]\r\n",
        "\r\n",
        "def single_loss(model, w,x,y):\r\n",
        "    prediction = get_parity_prediction(model, x,w)\r\n",
        "    return rel_ent(prediction, y)\r\n",
        "\r\n",
        "\r\n",
        "#initialise weights\r\n",
        "w = np.array(np.split(np.random.uniform(size=(40,),low=-1.0,high=1.0),10),requires_grad=True)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "EVs = np.array([])\r\n",
        "model = \"QNN\" # \"QNN\" or \"EQ\"\r\n",
        "\r\n",
        "shift = np.pi/2\r\n",
        "n_iter=1\r\n",
        "#for i in range(n_iter):\r\n",
        "  #initialise weights randomly\r\n",
        "#print(i)\r\n",
        "w = np.array(np.split(np.random.uniform(size=(40,),low=-1.0,high=1.0),10),requires_grad=True)\r\n",
        "Fisher = average_loss(w,data,shift,model)[1]\r\n",
        "#find eigenvalues and add to the list\r\n",
        "val, v = np.linalg.eig(Fisher)\r\n",
        "EVs =np.append(EVs,np.real(val))\r\n",
        "\r\n",
        "#plot histogram\r\n",
        "x, bins, p=plt.hist(EVs, bins=None,range=None)\r\n",
        "for item in p:\r\n",
        "  item.set_height(item.get_height()/(40*n_iter)) # normalise it\r\n",
        "plt.ylim(0,1)\r\n",
        "plt.title(model)\r\n",
        "plt.show()\r\n",
        "print(quantum_neural_network.draw())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-171-1b61b2013df1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 np.random.normal(loc=1, scale=variance)] for i in range(int(n_samples/2))],requires_grad=False)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'requires_grad' is an invalid keyword argument for array()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw_vDgqbYUfO",
        "outputId": "99f39f1a-9d6f-44a4-d044-fb4ebf37cde6"
      },
      "source": [
        "a = np.array([1.+0.2j, 2.+1j])\r\n",
        "print(a)\r\n",
        "print(np.real(a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.+0.2j 2.+1.j ]\n",
            "[1. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "519879BjEe2P",
        "outputId": "8246ad7a-dd9e-4a61-c8d6-fcdc254aa4ca"
      },
      "source": [
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import copy\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn import preprocessing\r\n",
        "\r\n",
        "#Torch for Classical NN\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "\r\n",
        "#PennyLane for QNN\r\n",
        "import pennylane as qml\r\n",
        "from pennylane.optimize import AdamOptimizer\r\n",
        "\r\n",
        "\r\n",
        "    \r\n",
        "# load IRIS dataset\r\n",
        "dataset = pd.read_csv('iris.csv')\r\n",
        "\r\n",
        "\r\n",
        "# transform species to numerics\r\n",
        "dataset.loc[dataset.species=='Iris-setosa', 'species'] = 0\r\n",
        "dataset.loc[dataset.species=='Iris-versicolor', 'species'] = 2\r\n",
        "dataset.loc[dataset.species=='Iris-virginica', 'species'] = 1\r\n",
        "dataset = dataset.query('species==0 or species==1')\r\n",
        "print(dataset.query('species==0 or species==1'))\r\n",
        "x = dataset.loc[0:,dataset.columns[0:4]].values #returns a numpy array\r\n",
        "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1,1))\r\n",
        "x_scaled = min_max_scaler.fit_transform(x)\r\n",
        "df = pd.DataFrame(x_scaled,columns=dataset.columns[0:4])\r\n",
        "\r\n",
        "\r\n",
        "print(df)\r\n",
        "\r\n",
        "#normalise\r\n",
        "train_X, train_Y = df.astype(float).values, dataset.species.astype(int).values\r\n",
        "print(train_Y)\r\n",
        "\r\n",
        "from pennylane import numpy as np\r\n",
        "train_X = np.array(train_X,requires_grad=False)\r\n",
        "train_Y = np.array(train_Y,requires_grad=False)\r\n",
        "\r\n",
        "data = list(zip(train_X,train_Y))\r\n",
        "dev = qml.device(\"default.qubit\", wires=5) \r\n",
        "\r\n",
        "\r\n",
        "#QUANTUM NEURAL NETWORK\r\n",
        "@qml.qnode(dev, diff_method='backprop')\r\n",
        "def quantum_neural_network(x, w):\r\n",
        "\r\n",
        "    #encoding\r\n",
        "    for i in range(4):\r\n",
        "        qml.Hadamard(wires=i)\r\n",
        "        qml.RZ(x[i],wires=i)\r\n",
        "\r\n",
        "    for i in range(4):\r\n",
        "        for j in range(i):\r\n",
        "            qml.CNOT(wires=[j,i])\r\n",
        "            qml.RZ(((np.pi-x[i])*(np.pi-x[j])),wires=[i])\r\n",
        "            qml.CNOT(wires=[j,i])\r\n",
        "\r\n",
        "    for i in range(4):\r\n",
        "        qml.RZ(x[i],wires=i)\r\n",
        "\r\n",
        "    for i in range(4):\r\n",
        "        for j in range(i):\r\n",
        "            qml.CNOT(wires=[j,i])\r\n",
        "            qml.RZ(((np.pi-x[i])*(np.pi-x[j])),wires=[i])\r\n",
        "            qml.CNOT(wires=[j,i])\r\n",
        "\r\n",
        "\r\n",
        "    #variational\r\n",
        "    for i in range(4):\r\n",
        "        qml.RY(w[0][i],wires=i)\r\n",
        "\r\n",
        "    qml.broadcast(qml.CNOT, wires=[0,1,2,3], pattern=\"all_to_all\", parameters=None, kwargs=None)\r\n",
        "\r\n",
        "    for i in range(4):\r\n",
        "        qml.RY(w[1][i],wires=i)\r\n",
        "\r\n",
        "    dev.shots = 10000\r\n",
        "\r\n",
        "    for i in range(4):\r\n",
        "      qml.CNOT(wires=[i,4])\r\n",
        "\r\n",
        "    return qml.expval(qml.PauliZ(wires=4))\r\n",
        "\r\n",
        "w = np.array(np.split(np.random.uniform(size=(8,),low=-1,high=1),2),requires_grad=True)\r\n",
        "print(quantum_neural_network(train_X[0],w))\r\n",
        "print(quantum_neural_network.draw())\r\n",
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     sepal_length  sepal_width  petal_length  petal_width species\n",
            "0             5.1          3.5           1.4          0.2       0\n",
            "1             4.9          3.0           1.4          0.2       0\n",
            "2             4.7          3.2           1.3          0.2       0\n",
            "3             4.6          3.1           1.5          0.2       0\n",
            "4             5.0          3.6           1.4          0.2       0\n",
            "..            ...          ...           ...          ...     ...\n",
            "145           6.7          3.0           5.2          2.3       1\n",
            "146           6.3          2.5           5.0          1.9       1\n",
            "147           6.5          3.0           5.2          2.0       1\n",
            "148           6.2          3.4           5.4          2.3       1\n",
            "149           5.9          3.0           5.1          1.8       1\n",
            "\n",
            "[100 rows x 5 columns]\n",
            "    sepal_length  sepal_width  petal_length  petal_width\n",
            "0      -0.555556     0.181818     -0.864407    -0.916667\n",
            "1      -0.666667    -0.272727     -0.864407    -0.916667\n",
            "2      -0.777778    -0.090909     -0.898305    -0.916667\n",
            "3      -0.833333    -0.181818     -0.830508    -0.916667\n",
            "4      -0.611111     0.272727     -0.864407    -0.916667\n",
            "..           ...          ...           ...          ...\n",
            "95      0.333333    -0.272727      0.423729     0.833333\n",
            "96      0.111111    -0.727273      0.355932     0.500000\n",
            "97      0.222222    -0.272727      0.423729     0.583333\n",
            "98      0.055556     0.090909      0.491525     0.833333\n",
            "99     -0.111111    -0.272727      0.389831     0.416667\n",
            "\n",
            "[100 rows x 4 columns]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "-0.013374894009908322\n",
            " 0: ──H──RZ(-0.556)──╭C────────────╭C──╭C────────────╭C──────╭C────────────────╭C───RZ(-0.556)──────────────────────────╭C────────────────────╭C───────────╭C────────────╭C──────╭C────────────────╭C───RY(-0.0477)───────────────────────────╭C─────────────────────────╭C──────╭C───RY(0.657)───────────────╭C─────────────────────────┤     \n",
            " 1: ──H──RZ(0.182)───╰X──RZ(10.9)──╰X──│─────────────│───╭C──│─────────────╭C──│───╭C───────────────────╭C───RZ(0.182)──╰X──────────RZ(10.9)──╰X───────────│─────────────│───╭C──│─────────────╭C──│───╭C────────────────────╭C───RY(-0.714)──╰X─────────────────────────│───╭C──│───╭C───────────RY(-0.943)──│──────────────╭C──────────┤     \n",
            " 2: ──H──RZ(-0.864)────────────────────╰X──RZ(14.8)──╰X──╰X──│───RZ(11.9)──╰X──│───│────────────────────│───╭C─────────────────────╭C──────────RZ(-0.864)──╰X──RZ(14.8)──╰X──╰X──│───RZ(11.9)──╰X──│───│─────────────────────│───╭C──────────────────────╭C──RY(-0.204)──╰X──╰X──│───│───────────╭C───────────│───RY(0.555)──│───╭C──────┤     \n",
            " 3: ──H──RZ(-0.917)──────────────────────────────────────────╰X──RZ(15)────────╰X──╰X───────────RZ(12)──╰X──╰X───────────RZ(16.3)──╰X──────────RZ(-0.917)────────────────────────╰X──RZ(15)────────╰X──╰X────────────RZ(12)──╰X──╰X────────────RZ(16.3)──╰X──RY(0.713)───────────╰X──╰X──────────╰X───────────│───RY(0.111)──│───│───╭C──┤     \n",
            " 4: ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╰X─────────────╰X──╰X──╰X──┤ ⟨Z⟩ \n",
            "\n",
            "     sepal_length  sepal_width  petal_length  petal_width species\n",
            "0             5.1          3.5           1.4          0.2       0\n",
            "1             4.9          3.0           1.4          0.2       0\n",
            "2             4.7          3.2           1.3          0.2       0\n",
            "3             4.6          3.1           1.5          0.2       0\n",
            "4             5.0          3.6           1.4          0.2       0\n",
            "..            ...          ...           ...          ...     ...\n",
            "145           6.7          3.0           5.2          2.3       1\n",
            "146           6.3          2.5           5.0          1.9       1\n",
            "147           6.5          3.0           5.2          2.0       1\n",
            "148           6.2          3.4           5.4          2.3       1\n",
            "149           5.9          3.0           5.1          1.8       1\n",
            "\n",
            "[100 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whtU6A6qP0Zy"
      },
      "source": [
        "def initialise_data():\r\n",
        "    n_samples = 100\r\n",
        "    variance = (np.pi/4)**2\r\n",
        "    X0 = np.array([[np.random.normal(loc=-np.pi/4, scale=variance), \r\n",
        "                    np.random.normal(loc=np.pi/4, scale=variance),\r\n",
        "                    np.random.normal(loc=-np.pi/4, scale=variance),\r\n",
        "                    np.random.normal(loc=np.pi/4, scale=variance)] for i in range(int(n_samples/2))],requires_grad=False)\r\n",
        "\r\n",
        "\r\n",
        "    X1 = np.array([[np.random.normal(loc=np.pi/4, scale=variance), \r\n",
        "                    np.random.normal(loc=-np.pi/4, scale=variance),\r\n",
        "                    np.random.normal(loc=np.pi/4, scale=variance),\r\n",
        "                    np.random.normal(loc=-np.pi/4, scale=variance)] for i in range(int(n_samples/2))],requires_grad=False)\r\n",
        "\r\n",
        "    X = np.append(X0, X1,0)\r\n",
        "\r\n",
        "    Y = np.append(np.array([0 for i in range(int(n_samples/2))],requires_grad=False),np.array([1 for i in range(int(n_samples/2))],requires_grad=False))\r\n",
        "\r\n",
        "    data = list(zip(X, Y))\r\n",
        "\r\n",
        "    return data\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "dev = qml.device(\"default.qubit\", wires=5)\r\n",
        "@qml.qnode(dev, diff_method='backprop', wires=5)\r\n",
        "def quantum_neural_network(x, w,depth):\r\n",
        "\r\n",
        "    #encoding circuit============================================================\r\n",
        "\r\n",
        "    #Hadamards\r\n",
        "    for i in range(4):\r\n",
        "        qml.Hadamard(wires=i)\r\n",
        "        \r\n",
        "    #Accounting for depth=0\r\n",
        "    if(depth==0):\r\n",
        "        for i in range(4):\r\n",
        "            qml.RZ(x[i],wires=i)\r\n",
        "\r\n",
        "    #Multiple encoding layers:\r\n",
        "    for k in range(depth):\r\n",
        "        #RZ gates\r\n",
        "        for i in range(4):\r\n",
        "            qml.RZ(x[i],wires=i)\r\n",
        "        #RZZ gates\r\n",
        "        for i in range(4):\r\n",
        "            for j in range(i):\r\n",
        "                qml.CNOT(wires=[j,i])\r\n",
        "                qml.RZ(((x[i])*(x[j])),wires=[i])\r\n",
        "                qml.CNOT(wires=[j,i])\r\n",
        "\r\n",
        "        \r\n",
        "    #variational circuit\r\n",
        "    for j in range(9):\r\n",
        "      for i in range(4):\r\n",
        "          qml.RY(w[j][i],wires=i)\r\n",
        "      qml.broadcast(qml.CNOT, wires=[0,1,2,3], pattern=\"all_to_all\", parameters=None, kwargs=None)\r\n",
        "\r\n",
        "    for i in range(4):\r\n",
        "        qml.RY(w[9][i],wires=i)\r\n",
        "\r\n",
        "    dev.shots = 1000\r\n",
        "    \r\n",
        "    for i in range(4):\r\n",
        "      qml.CNOT(wires=[i,4])\r\n",
        "    \r\n",
        "    return qml.expval(qml.PauliZ(wires=4))\r\n",
        "\r\n",
        "def get_parity_prediction(x,w,depth):\r\n",
        "    np_measurements = (quantum_neural_network(x,w,depth)+1.)/2.\r\n",
        "  \r\n",
        "    return np.array([np_measurements,1.-np_measurements])\r\n",
        "\r\n",
        "def single_loss(w,x,y,depth):\r\n",
        "    prediction = get_parity_prediction(x,w,depth)\r\n",
        "    return rel_ent(prediction, y)\r\n",
        "\r\n",
        "def rel_ent(pred,y):\r\n",
        "    return -np.log(pred)[int(y)]\r\n",
        "\r\n",
        "def average_loss(w, data,depth):\r\n",
        "  c = 0\r\n",
        "  Fisher = np.zeros((40,40))\r\n",
        "  for i,(x, y) in enumerate(data):\r\n",
        "    single_cost = single_loss(w,x,y,depth)\r\n",
        "    \r\n",
        "    c += single_cost\r\n",
        "    #print(single_cost)\r\n",
        "    grad_fn = qml.grad(single_loss,argnum=0)\r\n",
        "    gradient = grad_fn(w,x,y,depth).flatten()\r\n",
        "    #print(gradient)\r\n",
        "    #gradient = gradient/np.linalg.norm(gradient)\r\n",
        "    Fisher += np.outer(gradient,gradient)\r\n",
        "  \r\n",
        "  return c/len(data),Fisher/len(data)\r\n",
        "\r\n",
        "\r\n",
        "n_iter=5\r\n",
        "\r\n",
        "def get_all_fishers(n_iter,depth):\r\n",
        "  all_fishers = np.zeros((n_iter,40,40))\r\n",
        "  count = 0\r\n",
        "  data = initialise_data()\r\n",
        "  for i in range(n_iter):\r\n",
        "    w = np.array(np.split(np.random.uniform(size=(40,),low=-1.0,high=1.0),10),requires_grad=True)\r\n",
        "    Fisher = average_loss(w,data,depth)[1]\r\n",
        "    all_fishers[i]=Fisher\r\n",
        "  return all_fishers\r\n",
        "\r\n",
        "def normalise_fishers(Fishers):\r\n",
        "    num_samples = len(Fishers)\r\n",
        "    TrF_integral = (1 / num_samples) * np.sum([np.trace(F) for F in Fishers])\r\n",
        "    return [((40) / TrF_integral) * F for F in Fishers]\r\n",
        "\r\n",
        "\r\n",
        "def get_entropy(depth,n_iter=5,bins=10):\r\n",
        "  all_fishers = get_all_fishers(n_iter,depth)\r\n",
        "  normalised_fishers = normalise_fishers(all_fishers)\r\n",
        "  EVs = np.array([])\r\n",
        "  for F in normalised_fishers:\r\n",
        "    val, v = np.linalg.eig(F)\r\n",
        "    EVs = np.append(np.real(EVs),val)\r\n",
        "  x, bins, p=plt.hist(EVs, bins=bins)\r\n",
        "  entropy=0\r\n",
        "  x = x/len(EVs)\r\n",
        "  for i in x:\r\n",
        "    if(i!=0):\r\n",
        "      entropy-=i*np.log(i)\r\n",
        "  return entropy\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HHg2y0tVVOOs",
        "outputId": "74db1c0c-e3c1-4a68-8d0e-286b3b882c2e"
      },
      "source": [
        "std_rounds = 3\r\n",
        "depths = 15\r\n",
        "depth_entropies = np.zeros((depths,std_rounds))\r\n",
        "for depth in range(depths):\r\n",
        "  for j in range(std_rounds):\r\n",
        "    print(\"depth: \",depth, \" iteration: \",j)\r\n",
        "    depth_entropies[depth][j] = get_entropy(depth,n_iter=5)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "depth:  0  iteration:  0\n",
            "depth:  0  iteration:  1\n",
            "depth:  0  iteration:  2\n",
            "depth:  1  iteration:  0\n",
            "depth:  1  iteration:  1\n",
            "depth:  1  iteration:  2\n",
            "depth:  2  iteration:  0\n",
            "depth:  2  iteration:  1\n",
            "depth:  2  iteration:  2\n",
            "depth:  3  iteration:  0\n",
            "depth:  3  iteration:  1\n",
            "depth:  3  iteration:  2\n",
            "depth:  4  iteration:  0\n",
            "depth:  4  iteration:  1\n",
            "depth:  4  iteration:  2\n",
            "depth:  5  iteration:  0\n",
            "depth:  5  iteration:  1\n",
            "depth:  5  iteration:  2\n",
            "depth:  6  iteration:  0\n",
            "depth:  6  iteration:  1\n",
            "depth:  6  iteration:  2\n",
            "depth:  7  iteration:  0\n",
            "depth:  7  iteration:  1\n",
            "depth:  7  iteration:  2\n",
            "depth:  8  iteration:  0\n",
            "depth:  8  iteration:  1\n",
            "depth:  8  iteration:  2\n",
            "depth:  9  iteration:  0\n",
            "depth:  9  iteration:  1\n",
            "depth:  9  iteration:  2\n",
            "depth:  10  iteration:  0\n",
            "depth:  10  iteration:  1\n",
            "depth:  10  iteration:  2\n",
            "depth:  11  iteration:  0\n",
            "depth:  11  iteration:  1\n",
            "depth:  11  iteration:  2\n",
            "depth:  12  iteration:  0\n",
            "depth:  12  iteration:  1\n",
            "depth:  12  iteration:  2\n",
            "depth:  13  iteration:  0\n",
            "depth:  13  iteration:  1\n",
            "depth:  13  iteration:  2\n",
            "depth:  14  iteration:  0\n",
            "depth:  14  iteration:  1\n",
            "depth:  14  iteration:  2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZThGRbu6mzXC"
      },
      "source": [
        "depth_entropies_RX = np.load(\"/content/depth_entropies_RYRX.npy\")\r\n",
        "depth_entropies_RY = np.load(\"/content/depth_entropies.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfi9nKlZZiRV"
      },
      "source": [
        "mean_entropies_RX, std_entropies_RX = np.mean(depth_entropies_RX,axis=1),np.std(depth_entropies_RX,axis=1)\r\n",
        "mean_entropies_RY, std_entropies_RY = np.mean(depth_entropies_RY,axis=1),np.std(depth_entropies_RY,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "G0rtUoKfop3d",
        "outputId": "5293fbcc-9f6e-42de-edcc-c0073cb96f62"
      },
      "source": [
        "plt.errorbar(x=range(depths),y=mean_entropies_RX,yerr=std_entropies_RX,color='red',marker='+',ls=\" \",elinewidth=1,ecolor='black',label=\"RYRX\")\r\n",
        "plt.errorbar(x=range(depths),y=mean_entropies_RY,yerr=std_entropies_RY,color='green',marker='x',ls=\" \",elinewidth=1,ecolor='blue',label=\"RYRY\")\r\n",
        "plt.title(\"avg normalised Fisher spectrum entropy vs encoding depth\")\r\n",
        "plt.xlabel(\"encoding depth\")\r\n",
        "plt.ylabel(\"entropy (10 bins)\")\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIB5W5_V1Ucy"
      },
      "source": [
        "#SAME AS ABOVE W/ 8 TRAINABLE PARAMS\r\n",
        "def initialise_data():\r\n",
        "    n_samples = 100\r\n",
        "    variance = (np.pi/4)**2\r\n",
        "    X0 = np.array([[np.random.normal(loc=-np.pi/4, scale=variance), \r\n",
        "                    np.random.normal(loc=np.pi/4, scale=variance),\r\n",
        "                    np.random.normal(loc=-np.pi/4, scale=variance),\r\n",
        "                    np.random.normal(loc=np.pi/4, scale=variance)] for i in range(int(n_samples/2))],requires_grad=False)\r\n",
        "\r\n",
        "\r\n",
        "    X1 = np.array([[np.random.normal(loc=np.pi/4, scale=variance), \r\n",
        "                    np.random.normal(loc=-np.pi/4, scale=variance),\r\n",
        "                    np.random.normal(loc=np.pi/4, scale=variance),\r\n",
        "                    np.random.normal(loc=-np.pi/4, scale=variance)] for i in range(int(n_samples/2))],requires_grad=False)\r\n",
        "\r\n",
        "    X = np.append(X0, X1,0)\r\n",
        "\r\n",
        "    Y = np.append(np.array([0 for i in range(int(n_samples/2))],requires_grad=False),np.array([1 for i in range(int(n_samples/2))],requires_grad=False))\r\n",
        "\r\n",
        "    data = list(zip(X, Y))\r\n",
        "\r\n",
        "    return data\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "dev = qml.device(\"default.qubit\", wires=5)\r\n",
        "@qml.qnode(dev, diff_method='backprop', wires=5)\r\n",
        "def quantum_neural_network(x, w,depth):\r\n",
        "\r\n",
        "    #encoding circuit============================================================\r\n",
        "\r\n",
        "    #Hadamards\r\n",
        "    for i in range(4):\r\n",
        "        qml.Hadamard(wires=i)\r\n",
        "        \r\n",
        "    #Accounting for depth=0\r\n",
        "    if(depth==0):\r\n",
        "        for i in range(4):\r\n",
        "            qml.RZ(x[i],wires=i)\r\n",
        "\r\n",
        "    #Multiple encoding layers:\r\n",
        "    for k in range(depth):\r\n",
        "        #RZ gates\r\n",
        "        for i in range(4):\r\n",
        "            qml.RZ(x[i],wires=i)\r\n",
        "        #RZZ gates\r\n",
        "        for i in range(4):\r\n",
        "            for j in range(i):\r\n",
        "                qml.CNOT(wires=[j,i])\r\n",
        "                qml.RZ(((x[i])*(x[j])),wires=[i])\r\n",
        "                qml.CNOT(wires=[j,i])\r\n",
        "\r\n",
        "        \r\n",
        "    #variational circuit\r\n",
        "    for j in range(4):\r\n",
        "        qml.RY(w[0][j],wires=i)\r\n",
        "    qml.broadcast(qml.CNOT, wires=[0,1,2,3], pattern=\"all_to_all\", parameters=None, kwargs=None)\r\n",
        "\r\n",
        "    for i in range(4):\r\n",
        "        qml.RY(w[1][i],wires=i)\r\n",
        "\r\n",
        "    dev.shots = 1000\r\n",
        "    \r\n",
        "    for i in range(4):\r\n",
        "      qml.CNOT(wires=[i,4])\r\n",
        "    \r\n",
        "    return qml.expval(qml.PauliZ(wires=4))\r\n",
        "\r\n",
        "def get_parity_prediction(x,w,depth):\r\n",
        "    np_measurements = (quantum_neural_network(x,w,depth)+1.)/2.\r\n",
        "  \r\n",
        "    return np.array([np_measurements,1.-np_measurements])\r\n",
        "\r\n",
        "def single_loss(w,x,y,depth):\r\n",
        "    prediction = get_parity_prediction(x,w,depth)\r\n",
        "    return rel_ent(prediction, y)\r\n",
        "\r\n",
        "def rel_ent(pred,y):\r\n",
        "    return -np.log(pred)[int(y)]\r\n",
        "\r\n",
        "def average_loss(w, data,depth):\r\n",
        "  c = 0\r\n",
        "  Fisher = np.zeros((40,40))\r\n",
        "  for i,(x, y) in enumerate(data):\r\n",
        "    single_cost = single_loss(w,x,y,depth)\r\n",
        "    \r\n",
        "    c += single_cost\r\n",
        "    #print(single_cost)\r\n",
        "    grad_fn = qml.grad(single_loss,argnum=0)\r\n",
        "    gradient = grad_fn(w,x,y,depth).flatten()\r\n",
        "    #print(gradient)\r\n",
        "    #gradient = gradient/np.linalg.norm(gradient)\r\n",
        "    Fisher += np.outer(gradient,gradient)\r\n",
        "  \r\n",
        "  return c/len(data),Fisher/len(data)\r\n",
        "\r\n",
        "\r\n",
        "n_iter=5\r\n",
        "\r\n",
        "def get_all_fishers(n_iter,depth):\r\n",
        "  all_fishers = np.zeros((n_iter,40,40))\r\n",
        "  count = 0\r\n",
        "  data = initialise_data()\r\n",
        "  for i in range(n_iter):\r\n",
        "    w = np.array(np.split(np.random.uniform(size=(8,),low=-1.0,high=1.0),2),requires_grad=True)\r\n",
        "    Fisher = average_loss(w,data,depth)[1]\r\n",
        "    all_fishers[i]=Fisher\r\n",
        "  return all_fishers\r\n",
        "\r\n",
        "def normalise_fishers(Fishers):\r\n",
        "    num_samples = len(Fishers)\r\n",
        "    TrF_integral = (1 / num_samples) * np.sum([np.trace(F) for F in Fishers])\r\n",
        "    return [((40) / TrF_integral) * F for F in Fishers]\r\n",
        "\r\n",
        "\r\n",
        "def get_entropy(depth,n_iter=5,bins=10):\r\n",
        "  all_fishers = get_all_fishers(n_iter,depth)\r\n",
        "  normalised_fishers = normalise_fishers(all_fishers)\r\n",
        "  EVs = np.array([])\r\n",
        "  for F in normalised_fishers:\r\n",
        "    val, v = np.linalg.eig(F)\r\n",
        "    EVs = np.append(np.real(EVs),val)\r\n",
        "  x, bins, p=plt.hist(EVs, bins=bins)\r\n",
        "  entropy=0\r\n",
        "  x = x/len(EVs)\r\n",
        "  for i in x:\r\n",
        "    if(i!=0):\r\n",
        "      entropy-=i*np.log(i)\r\n",
        "  return entropy\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}